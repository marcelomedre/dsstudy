View(top_unique)
arrange(top_unique, unique)
arrange(top_unique, desc(unique)
)
arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
aubmit()
submit()
submit()
submit()
View(result3)
submit
submit()
submit
submit()
submit()
?mutate
submit()
submit()
submit()
submit()
submit()
submit()
1.007
1.007/70000
ans <- 1.07/70000
ans*20
1.07*20
21.4/70000
0.0003*100
install.packages("RMySQL", type = "source")
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user = "genome",
host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "Show databases;"); dbDisconnect(ucscDb)
result
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19",
host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affData <- dbReadTable(hg19, "affyU133Plus2")
head(affData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where mismatches between 1 and 3")
affMis <- fetch(query); quantile(affMis$misMatches)
affMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affMisSmall)
dbDisconnect(hg19)
library(httr)
require(httpuv)
install.packages("httpuv")
require(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("quiz2",
key = "7bb89f22156737b7958a",
secret = "2f8db11bd573309cac5c0435c75d0a80a6c0ccd8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
repo_list <- content(req)
repo_list
library(jsonlite)
json1 = repo_list
json2 = jsonlite::fromJSON(toJSON(json1))
View(json2)
View(json2)
View(json2)
xpathSApply(repo_list, "//datasharing", xmlValue)
repo <- c()
for (i in length(repo_list)){
repo <- repo_list[i]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
repo_list
head(repo_list)
list(repo_list$names, repo_list$created_at)
repo <- c()
for (i in length(repo_list)){
repo <- repo_list[i]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
for (i in 1:length(repo_list)){
repo <- repo_list[i]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
answer1 <- c()
for (i in 1:length(repo_list)) {
repo <- repo_list[[i]]
if (repo$name == "datasharing") {
answer1 = repo
break
}
}
if (length(answer1) == 0) {
msg("No such repository found: 'datasharing'")
} else {
msg("The repository 'datasharing' was created at", answer1$created_at)
}
repo <- c()
for (i in 1:length(repo_list)){
repo <- repo_list[[i]]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
our_repo
?msg
?message
if(length(our_repo) == 0){
message("No such repository found :'datasharing'")
}else {
message("The repository 'datasharing' was created at", our_repo$created_at)
}
install.packages("sqldf")
library(sqldf)
library(RMySQL)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url, destfile = "acs.csv", method = "auto")
survey <- read.csv("acs.csv")
survey <- read.csv("acs.csv", header = TRUE)
head(survey)
sqldf("Select pwgtp1 from acs where AGEP < 50")
acs <- read.csv("acs.csv", header = TRUE)
query 1 <- sqldf("Select pwgtp1 from acs where AGEP < 50")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", acs)
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "acs")
acs <- read.csv("acs.csv", sep =  ",", header = TRUE)
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "acs")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50")
?sqldf
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "RMySQL")
View(acs)
sqldf("Select pwgtp1 from acs where AGEP < 50")
fname <- "survey.csv"
download_if_not_exists(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
download.file(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
acs <- read.csv("acs.csv", header = TRUE, sep = ",")
answer2 <- sqldf("select pwgtp1 from acs where AGEP < 50")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
acs <- read.csv(f)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
library(RMySQL)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url, destfile = "acs.csv", method = "auto")
acs <- read.csv("acs.csv", sep =  ",", header = TRUE)
sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "SQLite")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "SQLite")
View(query1)
query2 <- sqldf("select pwgtp1 from acs", drv = "SQLite")
query3 <- sqldf("select * from acs where AGEP < 50", drv = "SQLite")
query4 <- sqldf("select * from acs", drv = "SQLite")
View(query2)
View(query3)
answer <- unique(acs$AGEP)
answer <- unique(acs$AGEP)
?identical
query1 <- sqldf("select unique AGEP from acs", drv = "SQLite")
query2 <- sqldf("select distinct AGEP from acs", drv = "SQLite")
query3 <- sqldf("select AGEP where unique from acs", drv = "SQLite")
query4 <- sqldf("select distinct pwgtp1 from acs", drv = "SQLite")
identical(answer, query1)
identical(answer, query2)
identical(answer, query3)
identical(answer, query4)
query1 <- sqldf("select unique AGEP from acs")
View(query2)
library(XML)
library(httr)
?nchar
library(XML)
library(httr)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
html <- readLines(con)
close(con)
answer <- c(nchar(html[10]), nchar(html[20]), nchar(html[30]), nchar(html[100]))
answer
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url, destfile = "data.for", method = "auto")
data <- read.fwf(data.for)
?read.fwf
lines <- readLines(url, n=10)
widths <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler",
"sstaNino12", "filler", "sstNino3", "filler", "sstaNino3",
"filler", "sstNino34", "filler", "sstaNino34", "filler",
"sstNino4", "filler", "sstaNino4")
data <- read.fwf(data.for, widths = widths, header = FALSE, skip = 4, col.names = colNames)
data <- read.fwf(url, widths = widths, header = FALSE, skip = 4, col.names = colNames)
data <- read.fwf("data.for", widths = widths, header = FALSE, skip = 4, col.names = colNames)
View(data)
answer <- sum(data[,4])
answer
View(data)
data <- read.fwf("data.for", widths = widths, header = FALSE, col.names = colNames)
View(data)
data <- read.fwf("data.for", widths = widths, header = FALSE, skip = 4, col.names = colNames)
?grep
d <- d[, grep("^[^filler]", names(d))]
d <- d[, grep("^[^filler]", names(data))]
data <- data[, grep("^[^filler]", names(data))]
sum(d[, 4])
sum(data[, 4])
View(data)
answer <- sum(data[,4])
answer
86.83*3
[0-9]+ (.*)[0-9]+
## Working with dates
d1 = date()
d1
class(d1)
s2 = Sys.Date()
class(d2)
d2 = Sys.Date()
class(d2)
format(d2, "%a" "%b" %c"")
format(d2, "%a "%b %c")
format(d2, "%a "%b %d")
format(d2, "%a "%b %d")
format(d2, "%a "%b %y")
format(d2, "%a "%b %y")
format(d2, "%a "%b %y")
x=c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z= as.Date(x, "%d%b%Y")
z
z[1]-z[2]
as.numeric(z[1-z[4]])
as.numeric(z[1]-z[4]])
as.numeric(z[1]-z[2]])
as.numeric(z[1]-z[2])
as.numeric(z[1]-z[4])
weedays(d2)
weekdays(d2)
months(d2)
julian(d2)
install.packages("lubridate")
library(lubridate)
ymd("20140108")
mdy("08/08/2015")
dmy("14/08/1988")
ymd_hms("14/08/1988 10:15:33")
ymd_hms("14-08-1988 10:15:33")
ymd_hms("2014-08-19 10:15:33")
ymd_hms("2014-08-19 10:15:33", tz = "Pacific/Auckland")
x=dmy(c("1jan1960", "2jan1960", "31mar1960", "30jul1960"))
wday(x[1])
wday(x[1], label = TRUE)
library(dplyr)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
if(file.exists("./data")){dir.create("./data")}
download.file(fileUrl, destfile = ".data/idaho_survey.csv", method = "auto")
download.file(fileUrl, destfile = ".idaho_survey.csv", method = "auto")
library(data.table)
getwd()
dataIdaho <- data.table(read.csv("idaho_survey.csv", stringsAsFactors = FALSE)
dataIdaho <- data.table(read.csv("idaho_survey.csv", stringsAsFactors = FALSE))
View(dataIdaho)
?strsplit
names(dataIdaho)
names <- names(dataIdaho)
strsplit(names, "wgtp")
strsplit(names, wgtp)
splittedData <- strsplit(names, "wgtp")
splittedData[123]
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl2, destfile = "GDP.csv", method = "auto")
dataGDP <- data.table(read.csv("GDP.csv", stringsAsFactors = FALSE))
View(dataGDP)
dataGDP <- data.table(read.csv("GDP.csv", skip = 4, stringsAsFactors = FALSE))
select(dataGDP, c("X", "X1", "X3", "X4"))
select(dataGDP, c(1, 2, 4, 5))
dataGDP <- select(dataGDP, c(1, 2, 4, 5))
?colnames
colnames(dataGDP) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP)
dataGDP$numGDP <- as.numeric(gsub(",","",dataGDP$GDP))
dataGDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE))
dataGDP <- select(dataGDP, c(1, 2, 4, 5))
colnames(dataGDP) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP)
dataGDP$numGDP <- as.numeric(gsub(",","",dataGDP$GDP))
average <- mean(dataGDP$numGDP)
average
?grep
grep("United$",Country), 3
grep("United$",Country)
grep("United$", dataGDP$Country)
grep("*United$", dataGDP$Country)
grep("^United",dataGDP$Country)
grep("^United",dataGDP$Country)
length(grep("United$", dataGDP$Country))
length(grep("*United$", dataGDP$Country))
length(grep("^United",dataGDP$Country))
length(grep("^United",dataGDP$Country))
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl3, destfile = "GDP_2.csv", method = "auto")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl4, destfile = "Educ.csv", method = "auto")
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl3, destfile = "GDP_2.csv", method = "auto")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl4, destfile = "Educ.csv", method = "auto")
dataGDP2 <- data.table(read.csv("GDP.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE))
dataGDP2 <- select(dataGDP2, c(1, 2, 4, 5))
colnames(dataGDP2) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP2)
dataEduc <- data.table(read.csv("Educ.csv", stringsAsFactors = FALSE))
View(dataEduc)
View(dataGDP)
View(dataEduc)
View(dataGDP2)
View(dataEduc)
?merge
dataEduc <- dataEduc[,c("CountryCode", "Special.Notes")]
fullData <- merge(dataGDP2,dataEduc, by.x = CountryCode, by.y = CountryCode)
fullData <- merge(dataGDP2,dataEduc, by.x = "CountryCode", by.y = "CountryCode")
View(fullData)
mergedData <- merge(dataGDP2,dataEduc, by.x = "CountryCode", by.y = "CountryCode")
?grep
?grpl
?grepl
length(grep("[Ff]iscal year end(*/)+ June" ), mergedData$Special.Notes)
length(grep("[Ff]iscal year end(*/)+ June", mergedData$Special.Notes))
length(grep("[Ff]iscal year (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year end: (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year end:(*/)+June", mergedData$Special.Notes))
length(grepl("^[Ff]iscal year end:(*/)+June", mergedData$Special.Notes))
View(mergedData)
mergedData$Special.Notes[grepl("^Fiscal year end: June 30", mergedData$Special.Notes)]
length(grep("^Fiscal year end: June 30", mergedData$Special.Notes))
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes <- data.table(sampleTimes)
View(sampleTimes)
?POSIXlt
?grep
sampleTimes12 <- grep("^2012", sampleTimes)
sampleTimes12 <- sampleTimes[grep("^2012", sampleTimes)]
View(sampleTimes12)
?wday
sapply(sampleTimes12, wday)
sampleTimes12Mon <- sapply(sampleTimes12, wday)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday))
View(sampleTimes12Mon)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(..., label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(... , label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday))
wday(sampleTimes12Mon, label = TRUE)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, weekdays))
View(sampleTimes12Mon)
?n
MOndays <- length(sampleTimes12Mon[grepl("segunda-feira", sampleTimes12Mon)])
MOndays
length(sampleTimes12Mon[grepl("segunda-feira", sampleTimes12Mon$sampleTimes)])
length(sampleTimes12Mon[grep("segunda-feira", sampleTimes12Mon$sampleTimes)])
length(sampleTimes12Mon(grep("segunda-feira", sampleTimes12Mon$sampleTimes)))
sampleTimes12Mon(grep("segunda-feira", sampleTimes12Mon$sampleTimes))
length(which(wday(sampleTimes12Mon, label = T) == "segunda-feira"))
length(which(sampleTimes12Mon$sampleTimes == "segunda-feira"))
Mondays <- length(which(sampleTimes12Mon$sampleTimes == "segunda-feira"))
Mondays
36.92/6
library(ggplot2)
testdat <- data.frame(x = 1:100, y = rnorm(100))
plot(testdat$x, testdat$y, type = 'l', ylim = c(-3,3))
testdat[50,2] <- 100
plot(testdat$x, testdat$y, type = 'l', ylim = c(-3,3))
library(ggplot2)
g <- ggplot(testdat, aes(x = x, y = y))
g + geom_line()
g + geom_line + ylim(-3,3)
g + geom_line() + ylim(-3,3)
g + geom_line() + coord_cartesian(ylim = c(3,-3))
set.seed(12345)
par(mar = rep (0.2, 4))
dataMatrix <- matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(dataMatrix)[,nrow(dataMatrix):1])
par(mar = rep(0.2, 4))
heatmap(dataMatrix)
set.seed(678910)
set.seed(678910)
for (i in 1:40){
#flip a coin
coinFlip <- rbinom(1, size = 1, prob = 0.5)
# if a coin is heads add a common pattern to the row
if (coinFlip){
dataMatrix[i,] <- dataMatrix[i,] + rep(c(0, 3), each = 5)
}
}
par(mar = rep(0.2, 4))
heatmap(dataMatrix)
image(1:10, 1:40, t(dataMatrix)[,nrow(dataMatrix):1])
heatmap(dataMatrix)
hh <- hclust(dist(dataMatrix))
dataMatrixOrdered <- dataMatrix[hh$order,]
par(mfrow = c(1,3))
image(t(dataMatrixOrdered)[, nrow(dataMatrixOrdered):1])
plot(rowMeans(dataMatrixOrdered), 40:1, xlab = "Row Mean", ylab = "Row", pch = 19)
plot(colMeans(dataMatrixOrdered), xlab = "Column", ylab = "Column Mean", pch = 19)
library(rmarkdown)
render("1-example.Rmd", output_format = "word_document")
rmarkdown::render("analysis.R")
# CraftBeers dataset
# Exploring craft Brewery data
setwd("C:/Users/Marcelo/Desktop/DsStudy/CraftBeers")
library(dplyr)
library(data.table)
library(ggplot2)
library(rmarkdown)
df_beer <- data.table(read.csv("beers.csv", header = TRUE,
stringsAsFactors = FALSE))
df_brew <- data.table(read.csv("breweries.csv", header = TRUE,
stringsAsFactors = FALSE))
colnames(df_brew) <- c("brewery_id", "name", "city", "state")
str(df_beer)
str(df_brew)
summary(df_beer)
summary(df_brew)
head(df_brew)
head(df_beer)
full_beer_data <- merge(df_beer, df_brew, by = "brewery_id")
head(full_beer_data)
names(full_beer_data)
colnames(full_beer_data) <- c("brewery_id", "X", "abv", "ibu", "id", "beer_name",
"style", "ounces", "brewery_name", "city", "state")
# Dropping repeated columns
full_beer_data = full_beer_data[,3:11]
# transforming ABV into %
full_beer_data$abv = full_beer_data$abv*100
head(full_beer_data)
# Number of breweries x State
breweryxstate <- full_beer_data %>%
group_by(brewery_name)%>%
group_by(state)%>%
summarise(Freq = n())
ggplot(data = breweryxstate, aes(x = reorder(state, -Freq), y = Freq)) +
geom_bar(stat="identity") +
labs(x = "State", y = "Brewery Freq") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
geom_hline(yintercept=mean(breweryxstate$Freq), col = "red")
# Number of breweries x State
breweryxcity <- full_beer_data %>%
group_by(brewery_name) %>%
group_by(city) %>%
summarise(Freq = n())
# subsetting for cities with more than 10 breweries
breweryxcity = breweryxcity[which(breweryxcity[,2]>10),]
ggplot(data = breweryxcity, aes(x = reorder(city, -Freq), y = Freq)) +
geom_bar(stat="identity", col = "green") +
labs(x = "City", y = "Number of Breweries", title = "Cities with Most Breweries") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
geom_hline(yintercept=mean(breweryxcity$Freq), col = "red")
# Beer with highest average alcohol content
abvxstyle <- full_beer_data %>%
filter(!is.na(abv)) %>%
group_by(abv)%>%
group_by(style) %>%
summarise(Mean = sum(abv)/n())
ggplot(data = abvxstyle, aes(x = reorder(style, -Mean), y = Mean)) +
geom_bar(stat="identity", col = "green") +
labs(x = "Style", y = "average % Alcohol",
title = "Beers with highest average alcohol") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
geom_hline(yintercept=mean(abvxstyle$Mean), col = "red")
# Beers with more than 6% of alcohol content
abvxstyle = abvxstyle[which(abvxstyle[,2]>6),]
ggplot(data = abvxstyle, aes(x = reorder(style, -Mean), y = Mean)) +
geom_bar(stat="identity", col = "green") +
labs(x = "Style", y = "average % Alcohol",
title = "Beers with highest average alcohol") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
geom_hline(yintercept=mean(abvxstyle$Mean), col = "red")
# Most brewed Beer Styles
beerxstyle <- full_beer_data %>%
group_by(beer_name)%>%
group_by(style) %>%
summarise(Sum = n())
beerxstyle = beerxstyle[which(beerxstyle[,2]>20),]
ggplot(data = beerxstyle, aes(x = reorder(style, -Sum), y = Sum)) +
geom_bar(stat="identity", col = "grey") +
labs(x = "Style", y = "# of Beers",
title = "Most brewed Beer Styles") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Outcomes
# - Colorado is the state with the highest number of breweries, followed by California and Minesota
# - Grand Rapids, Portland and Chicago are the cities with the highest beer consume - NICE PLACES TO VISIT
# - English Barleywine and Quadrupel present the highest alcohol content in % volume
# - American IPA is by far the most brewed Beer Style
rmarkdown::render("analysis.R")
rmarkdown::render("craft_brewery_01.R")
